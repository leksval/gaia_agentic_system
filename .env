# --- Choose LLM Provider ---
# Set to openrouter or ollama
LLM_PROVIDER=openrouter

# --- OpenRouter Configuration (if LLM_PROVIDER=openrouter) ---
OPENROUTER_API_KEY=sk-or-v1-api
# Available models:
# OPENROUTER_MODEL_NAME=google/gemini-2.5-pro-preview
# OPENROUTER_MODEL_NAME=anthropic/claude-3-haiku-20240307
# OPENROUTER_MODEL_NAME=mistral/mistral-7b-instruct-v0.2
OPENROUTER_MODEL_NAME=openai/gpt-3.5-turbo
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1 # Default usually fine

# --- Ollama Configuration (if LLM_PROVIDER=ollama) ---
OLLAMA_MODEL_NAME=llama3:8b-instruct
# Adjust if your Ollama is not accessible via default Docker host mapping
OLLAMA_BASE_URL=http://host.docker.internal:11434

# --- Tool Configuration ---
TAVILY_API_KEY=tvly-dev-api

# --- Agent Configuration ---
MAX_AGENT_ITERATIONS=7